{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e530fd-0db7-4812-b54b-2523533eeee5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A Bio-Image Analysis chatbot GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6350ba6b-7448-4ba2-8e96-704055decdf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Jupyter notebook can be used to build a graphical user interface for a chatbot. \n",
    "# Just run this from the terminal:\n",
    "#\n",
    "# voila gui.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492f8ff-1e8c-4233-b29f-da8fa198198a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7cf15-095d-471e-9e68-5ee4518a7c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo: replace this function with any other prompt function from the chatbot.ipynb notebook\n",
    "def prompt_chatGPT(message:str, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"A prompt helper function that sends a message to openAI\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # convert message in the right format if necessary\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "    # setup connection to the LLM\n",
    "    client = openai.OpenAI()\n",
    "    # todo: enter your API key here:\n",
    "    # client.api_key = \"\"\n",
    "    client.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "    \n",
    "    # submit prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=message\n",
    "    )\n",
    "    \n",
    "    # extract answer\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14ebdc-f163-46d3-b467-57418ac45c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = prompt_chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723e248-b35d-4749-95f3-ffe4092b1f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "def prompt_with_memory(message:str):\n",
    "    \n",
    "    # convert message in the right format and store it in memory\n",
    "    question = {\"role\": \"user\", \"content\": message}\n",
    "    chat_history.append(question)\n",
    "    \n",
    "    # receive answer\n",
    "    response = prompt(chat_history)\n",
    "    \n",
    "    # convert answer in the right format and store it in memory\n",
    "    answer = {\"role\": \"assistant\", \"content\": message}\n",
    "    chat_history.append(answer)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53730f18-5cbf-4036-9951-eae028af22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can inject knowledge into the chatbot, by telling things the user of our chatbot won't see.\n",
    "\n",
    "_ = prompt_with_memory(\"\"\"\n",
    "You are an extremely talented Bio-image analyst, but you cannot code.\n",
    "You are an excellent theoretician who knows which algorithm or software to use.\n",
    "You use preferably classical image processing algorithms.\n",
    "\n",
    "You use the word \"ehm\" at random places in sentences. Every second sentence contains \"ehm\" or \"ehhh\".\n",
    "You are also rude and pedantic. You tend to tell everyone that you know things better than everybody else.\n",
    "Keep your answers 2-3 sentences short.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0371c20-9d7c-4393-8a64-0105ad2d7e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create widgets\n",
    "output_label = widgets.HTML(value=\"\")\n",
    "text_input = widgets.Text(placeholder=\"Type something here...\")\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "def on_submit(e):\n",
    "    question = text_input.value\n",
    "    if len(question) == 0:\n",
    "        return\n",
    "    text_input.value = \"\"\n",
    "\n",
    "    # submit prompt to LLM\n",
    "    answer = prompt_with_memory(question)\n",
    "\n",
    "    # Append question and answer to the existing HTML content\n",
    "    output_label.value += f\"\"\"\n",
    "    <div style='text-align:right; color: blue; font-size: 20px'>{question}</div>\n",
    "    <div style='text-align:left; color: darkgreen; font-size: 20px'>{answer}</div>\n",
    "    \"\"\"\n",
    "\n",
    "# Attach the event handler to the text field and the button\n",
    "text_input.continuous_update = False\n",
    "text_input.observe(on_submit)\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Arrange the widgets for display\n",
    "display(output_label, widgets.HBox([text_input, submit_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd410c91-445f-4e28-b789-6031f6c74593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
