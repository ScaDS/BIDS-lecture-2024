{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b56f6f-559c-4c78-8fad-69082a717617",
   "metadata": {},
   "source": [
    "# Powerful system messages\n",
    "In this notebook we will generate image analysis code using a detailed system prompt. The system prompt contains generic instructions and specific bio-image analysis knowledge. The knowledge is stored in a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebb70ea-c2b5-462a-9135-1f11b634b55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8921ccc-26ff-47a8-896c-080f66987fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "* Displays an image with a slider and label showing mouse position and intensity.\n",
       "```python\n",
       "stackview.annotate(image, labels)\n",
       "```\n",
       "\n",
       "* Allows cropping an image along all axes.\n",
       "```python\n",
       "stackview.crop(image)\n",
       "```\n",
       "\n",
       "* Showing an image stored in variable `image` and a segmented image stored in variable `labels` on top. Also works with two images or two label images.\n",
       "```python\n",
       "stackview.curtain(image, labels, alpha: float = 1)\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'code_snippets.txt'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    knowledge = file.read()\n",
    "    \n",
    "Markdown(knowledge[:428])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b464e-2446-423e-b646-6a3cc530f47d",
   "metadata": {},
   "source": [
    "We use this content and the following instructions to assemble a system message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b893cb7-a8cd-474c-bc4a-8a4275664cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are a extremely talented bioimage analyst and you use Python to solve your tasks.\n",
    "If the request entails writing code, write concise professional, high-quality bioimage analysis code.\n",
    "\n",
    "## Python specific instructions\n",
    "\n",
    "You can only use those Python libraries: scikit-image,numpy,scipy,pandas,matplotlib,seaborn,scikit-learn,stackview,torch,cellpose,stardist,n2v,pyclesperanto_prototype,apoc,napari-segment-blobs-and-things-with-membranes,napari-simpleitk-image-processing,napari-skimage-regionprops,skan,os,dask,czifile.\n",
    "If the user asks for those simple tasks, use these code snippets.\n",
    "\n",
    "{knowledge}\n",
    "\n",
    "## Todos\n",
    "\n",
    "Answer your response in three sections:\n",
    "1. Summary: First provide a short summary of the task.\n",
    "2. Plan: Provide a concise step-by-step plan without any code.\n",
    "3. Code: Provide the code.\n",
    "\n",
    "Structure it with markdown headings like this:\n",
    "\n",
    "### Summary\n",
    "I will do this and that.\n",
    "\n",
    "### Plan\n",
    "1. Do this.\n",
    "2. Do that.\n",
    "\n",
    "### Code\n",
    "```\n",
    "this()\n",
    "that()\n",
    "```\n",
    "\n",
    "## Final remarks\n",
    "\n",
    "The following points have highest importance and may overwrite the instructions above.\n",
    "Make sure to provide 1) summary, 2) plan and 3) code.\n",
    "Make sure to keep your answer concise and to the point. \n",
    "Make sure the code you write is correct and can be executed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f9559-2bdb-49c8-af58-4079d149f370",
   "metadata": {},
   "source": [
    "Note the following helper function shows how we integrate the system message into the list of messages submitted to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd927ba-3157-4f4d-abbc-fe62ed887afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt(message:str, system_message:str=None, model=\"gpt-4o\"):\n",
    "    \"\"\"A prompt helper function that sends a message to openAI\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    import openai\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    messages = []\n",
    "    if system_message is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": system_message}]\n",
    "    messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b76dd4-98bb-4862-80cd-85ccee258724",
   "metadata": {},
   "source": [
    "Our question refers to a function that is listed in our knowledge base, but might not be know to ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e505a018-14f1-4af1-a219-e1397ec58666",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"How can I segment an image using Otsu's method, spot detection and Voronoi-tesselation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a2f985-d6df-4cc7-95e7-f979c9f2b439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary\n",
       "I will segment an image using Otsu's method, spot detection, and Voronoi-tessellation by leveraging the `cle.voronoi_otsu_labeling` function from the `pyclesperanto_prototype` library.\n",
       "\n",
       "### Plan\n",
       "1. Load the image that needs to be segmented.\n",
       "2. Use the `cle.voronoi_otsu_labeling` function to perform Otsu's thresholding, spot detection, and Voronoi-tessellation on the image.\n",
       "3. Visualize the segmented image.\n",
       "\n",
       "### Code\n",
       "```python\n",
       "import pyclesperanto_prototype as cle\n",
       "import stackview\n",
       "from skimage.io import imread\n",
       "\n",
       "# Step 1: Load the image\n",
       "image = imread('path_to_image.tif')  # Replace with the actual path to your image\n",
       "\n",
       "# Step 2: Perform segmentation using Otsu's method, spot detection, and Voronoi-tessellation\n",
       "segmented_image = cle.voronoi_otsu_labeling(image, spot_sigma=2, outline_sigma=2)\n",
       "\n",
       "# Step 3: Visualize the segmented image\n",
       "stackview.insight(segmented_image)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1 = prompt(my_question, system_message=system_message)\n",
    "\n",
    "Markdown(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece2f67-40e6-4908-8818-c81149564563",
   "metadata": {},
   "source": [
    "As comparison, we submit the same request again, but this time without the system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae604c5d-4605-40cc-b954-55d3577ac3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Otsu's method, spot detection, and Voronoi tessellation can be combined to segment an image in a meaningful way. Hereâ€™s a step-by-step outline of how you can do this:\n",
       "\n",
       "1. **Otsu's Method for Initial Segmentation**:\n",
       "   - **Otsu's method** is used to perform automatic thresholding which separates the foreground (relevant objects) from the background based on their intensity levels.\n",
       "   - Here's how you can implement it:\n",
       "     ```python\n",
       "     import cv2\n",
       "     import numpy as np\n",
       "     import matplotlib.pyplot as plt\n",
       "\n",
       "     # Load the image\n",
       "     image = cv2.imread('path/to/image.jpg', cv2.IMREAD_GRAYSCALE)\n",
       "\n",
       "     # Apply Otsu's thresholding\n",
       "     ret, otsu_threshold = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
       "\n",
       "     # Display the result\n",
       "     plt.imshow(otsu_threshold, cmap='gray')\n",
       "     plt.title(\"Otsu's Thresholding\")\n",
       "     plt.show()\n",
       "     ```\n",
       "\n",
       "2. **Spot Detection using blob detection**:\n",
       "   - To detect spots in the image, you can use techniques such as **Blob Detection**.\n",
       "   - One popular approach is using the `SimpleBlobDetector` provided by OpenCV.\n",
       "     ```python\n",
       "     # Set up the SimpleBlobDetector with default parameters\n",
       "     params = cv2.SimpleBlobDetector_Params()\n",
       "     detector = cv2.SimpleBlobDetector_create(params)\n",
       "\n",
       "     # Detect blobs\n",
       "     keypoints = detector.detect(otsu_threshold)\n",
       "\n",
       "     # Draw detected blobs as red circles\n",
       "     blobs = cv2.drawKeypoints(image, keypoints, np.zeros((1,1)), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
       "\n",
       "     # Display the result\n",
       "     plt.imshow(blobs, cmap='gray')\n",
       "     plt.title(\"Blob Detection\")\n",
       "     plt.show()\n",
       "     ```\n",
       "\n",
       "3. **Voronoi Tessellation**:\n",
       "   - To apply Voronoi Tessellation, you need the coordinates of the detected spots from the previous step.\n",
       "   - OpenCV or SciPy can be used for computing the Voronoi diagram.\n",
       "     ```python\n",
       "     from scipy.spatial import Voronoi, voronoi_plot_2d\n",
       "\n",
       "     # Extract the coordinates of the keypoints\n",
       "     points = np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
       "\n",
       "     # Compute Voronoi tessellation\n",
       "     vor = Voronoi(points)\n",
       "\n",
       "     # Plot the Voronoi diagram\n",
       "     voronoi_plot_2d(vor)\n",
       "     plt.title(\"Voronoi Tessellation\")\n",
       "     plt.show()\n",
       "     ```\n",
       "\n",
       "4. **Combining Results**:\n",
       "   - Finally, combine the results from Otsuâ€™s segmentation, blob detection, and Voronoi tesselation to interpret and analyze the segmented regions within the image.\n",
       "\n",
       "     This may involve masking and labeling the areas defined by the Voronoi cells:\n",
       "     ```python\n",
       "     regions, vertices = voronoi_finite_polygons_2d(vor)\n",
       "     for region in regions:\n",
       "         polygon = vertices[region]\n",
       "         # Optionally: Mask and process each polygon with respect to the original image\n",
       "         # to identify and segment specific regions.\n",
       "     ```\n",
       "\n",
       "### Complete Code Example:\n",
       "```python\n",
       "import cv2\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
       "\n",
       "def voronoi_finite_polygons_2d(vor, radius=None):\n",
       "    new_regions = []\n",
       "    new_vertices = vor.vertices.tolist()\n",
       "\n",
       "    center = vor.points.mean(axis=0)\n",
       "    if radius is None:\n",
       "        radius = vor.points.ptp().max()\n",
       "\n",
       "    all_ridges = {}\n",
       "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
       "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
       "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
       "\n",
       "    for p1, region in enumerate(vor.point_region):\n",
       "        vertices = vor.regions[region]\n",
       "        if all(v >= 0 for v in vertices):\n",
       "            new_regions.append(vertices)\n",
       "            continue\n",
       "\n",
       "        ridges = all_ridges[p1]\n",
       "        new_region = [v for v in vertices if v >= 0]\n",
       "\n",
       "        for p2, v1, v2 in ridges:\n",
       "            if v2 < 0:\n",
       "                v1, v2 = v2, v1\n",
       "            if v1 >= 0:\n",
       "                continue\n",
       "\n",
       "            t = vor.points[p2] - vor.points[p1]\n",
       "            t /= np.linalg.norm(t)\n",
       "            n = np.array([-t[1], t[0]])\n",
       "\n",
       "            midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
       "            direction = np.sign(np.dot(midpoint - center, n)) * n\n",
       "\n",
       "            far_point = vor.vertices[v2] + direction * radius\n",
       "\n",
       "            new_region.append(len(new_vertices))\n",
       "            new_vertices.append(far_point.tolist())\n",
       "\n",
       "        vs = np.asarray([new_vertices[v] for v in new_region])\n",
       "        c = vs.mean(axis=0)\n",
       "        angles = np.arctan2(vs[:, 1] - c[1], vs[:, 0] - c[0])\n",
       "        new_region = np.array(new_region)[np.argsort(angles)]\n",
       "\n",
       "        new_regions.append(new_region.tolist())\n",
       "\n",
       "    return new_regions, np.asarray(new_vertices)\n",
       "\n",
       "# Load the image\n",
       "image = cv2.imread('path/to/image.jpg', cv2.IMREAD_GRAYSCALE)\n",
       "\n",
       "# Apply Otsu's thresholding\n",
       "ret, otsu_threshold = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
       "\n",
       "# Set up the SimpleBlobDetector with default parameters\n",
       "params = cv2.SimpleBlobDetector_Params()\n",
       "detector = cv2.SimpleBlobDetector_create(params)\n",
       "\n",
       "# Detect blobs\n",
       "keypoints = detector.detect(otsu_threshold)\n",
       "\n",
       "# Draw detected blobs as red circles\n",
       "blobs = cv2.drawKeypoints(image, keypoints, np.zeros((1,1)), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
       "\n",
       "# Display the blobs\n",
       "plt.imshow(blobs, cmap='gray')\n",
       "plt.title(\"Blob Detection\")\n",
       "plt.show()\n",
       "\n",
       "# Extract the coordinates of the keypoints\n",
       "points = np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
       "\n",
       "# Compute Voronoi tessellation\n",
       "vor = Voronoi(points)\n",
       "\n",
       "# Generate finite polygons\n",
       "regions, vertices = voronoi_finite_polygons_2d(vor)\n",
       "\n",
       "# Plot the Voronoi diagram\n",
       "plt.figure()\n",
       "voronoi_plot_2d(vor)\n",
       "plt.title(\"Voronoi Tessellation\")\n",
       "\n",
       "for region in regions:\n",
       "    polygon = vertices[region]\n",
       "    plt.fill(*zip(*polygon), edgecolor='k', alpha=0.4)\n",
       "\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "This complete example integrates all steps and will help you segment the image visually and analytically using Otsu's method, spot detection, and Voronoi tesselation. The outlined steps can be further refined based on specific needs and image characteristics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer2 = prompt(my_question)\n",
    "\n",
    "Markdown(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97473b0f-6680-4905-b5c0-5df75e2bb6b2",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Modify the knowledge base. Remove the information about Voronoi-Otsu-Labeling and run this notebook again.\n",
    "\n",
    "Optional exercise: Add more knowledge into the knowledge file and test if the language model gets it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f8951-1154-4f31-bf55-ef75b1ad1215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
